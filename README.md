# ğŸš€ GPU-Accelerated Processing Framework

## ğŸ‘¤ Author
**Emanuele Nardone**

## ğŸ“Œ Overview
A **containerized application** that performs **GPU-accelerated processing tasks** using PyTorch, designed to run in a **Seeweb Serverless GPU Cluster** with **NVIDIA A6000 GPUs**. The framework supports two primary processing modes:

1. ğŸ”¢ **Matrix Multiplication Benchmark**: Compares CPU and GPU performance for various matrix sizes.
2. ğŸ–¼ **Image Processing Pipeline**: Applies transformations using both CPU and GPU, including **Gaussian blur** and **color adjustments**.

ğŸ“‚ Results are stored in **S3-compatible storage**, and container images are managed through **GitHub Container Registry (GHCR)**.

---

## âœ¨ Features

### ğŸ”¥ Core Features
âœ… Dual processing modes: **Matrix multiplication** and **Image processing**  
âœ… **Automatic GPU detection** with CPU fallback  
âœ… **Detailed performance metrics** and speedup calculations  
âœ… **Rich CLI output** with colored performance indicators  
âœ… **S3-compatible storage integration**  
âœ… **Comprehensive logging system**  
âœ… Configurable via **CLI arguments** or **environment variables**  

### ğŸ”¢ Matrix Processing Features
ğŸ”¹ Configurable matrix sizes for benchmarking  
ğŸ”¹ PyTorch-based **CPU vs GPU computations**  
ğŸ”¹ **Memory-efficient** large matrix handling  

### ğŸ–¼ Image Processing Features
ğŸ¨ Batch image processing capabilities  
ğŸ¨ **Gaussian blur** and **color adjustment** transformations  
ğŸ¨ Support for **PNG, JPG, JPEG** formats  
ğŸ¨ **Parallel processing** optimization  

### ğŸ— Infrastructure Features
ğŸ›  **NVIDIA CUDA 11.8.0 runtime** support  
ğŸ›  **Kubernetes integration** with GPU resource management  
ğŸ›  **GitHub Actions CI/CD pipeline**  
ğŸ›  **Exponential backoff retry mechanism** for S3 operations  

---

## ğŸ“ Project Structure
```bash
k8s_test/
â”œâ”€â”€ benchmark_operations/      # ğŸ”¢ Matrix multiplication operations
â”‚   â””â”€â”€ benchmark_operations.py
â”œâ”€â”€ image_processing/         # ğŸ–¼ Image processing operations
â”‚   â””â”€â”€ image_processing_operations.py
â”œâ”€â”€ cli_operations/          # ğŸ› Command-line interface handling
â”‚   â””â”€â”€ cli_operations.py
â”œâ”€â”€ config/                  # âš™ï¸ Configuration management
â”‚   â””â”€â”€ s3_config_handler.py
â”œâ”€â”€ s3_operations/          # â˜ï¸ S3 storage operations
â”‚   â”œâ”€â”€ s3_client.py       # ğŸ”— Low-level S3 client with retry logic
â”‚   â””â”€â”€ s3_operations.py   # ğŸ“¦ High-level S3 operations
â”œâ”€â”€ .env.test              # ğŸŒ Environment variables template
â”œâ”€â”€ .gitignore             # ğŸš« Git ignore rules
â”œâ”€â”€ Dockerfile             # ğŸ³ NVIDIA CUDA-based container configuration
â”œâ”€â”€ main.py               # ğŸ¯ Application entry point
â”œâ”€â”€ python_image.yml      # ğŸ“œ Kubernetes pod configuration
â””â”€â”€ requirements.txt      # ğŸ“Œ Python dependencies
```

---

## âš ï¸ Prerequisites
ğŸ”¹ **Kubernetes cluster** with NVIDIA GPU support  
ğŸ”¹ **NVIDIA Container Toolkit**  
ğŸ”¹ **Access to GitHub Container Registry**  
ğŸ”¹ **S3-compatible storage**  
ğŸ”¹ **kubectl CLI tool**  
ğŸ”¹ **Python 3.8+** (for local development)  

---

## ğŸ“¦ Local Development with uv

This project uses [uv](https://github.com/astral-sh/uv) for extremely fast Python package management.

### ğŸ“¥ Installation
Using the standalone installer (recommended):

```bash
# On Windows (PowerShell)
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# On macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### ğŸš€ Getting Started

1. **Initialize the Environment**:
   This will create the virtual environment and install all dependencies defined in `pyproject.toml`.
   ```bash
   uv sync
   ```

2. **Run the Application**:
   Execute the script within the managed environment:
   ```bash
   uv run python main.py
   ```

3. **Managing Dependencies**:
   - **Add a new package**:
     ```bash
     uv add <package_name>
     ```
   - **Remove a package**:
     ```bash
     uv remove <package_name>
     ```
   - **Update dependencies**:
     ```bash
     uv lock --upgrade
     ```

---

## ğŸ”§ Environment Variables
Create a `.env` file based on `.env.test`:
```bash
# â˜ï¸ S3 Configuration
S3_ENDPOINT_URL=your-s3-endpoint
AWS_ACCESS_KEY_ID=your-access-key
AWS_SECRET_ACCESS_KEY=your-secret-key
S3_BUCKET=your-bucket-name

# ğŸ”§ Processing Configuration
PROCESSING_MODE=matrix|image  # Optional, defaults to matrix
MATRIX_SIZES=1000,2000,3000  # Optional for matrix mode
RAW_IMAGES_FOLDER=RawImages  # Optional for image mode
PROCESSED_IMAGES_FOLDER=ProcessedImages  # Optional for image mode
RESULTS_FOLDER=benchmark_results  # Optional
```

---

## ğŸš€ Kubernetes Deployment

### ğŸ–¥ 1. GPU Runtime Configuration
```yaml
spec:
  runtimeClassName: seeweb-nvidia-1xa6000
  containers:
    - resources:
        limits:
          nvidia.com/gpu: "1"
```

### ğŸ”‘ 2. Create Required Secrets
```bash
# GitHub Container Registry credentials
kubectl create secret docker-registry ghcr-secret \
  --docker-server=ghcr.io \
  --docker-username=YOUR_GITHUB_USERNAME \
  --docker-password=YOUR_GITHUB_PAT \
  --docker-email=YOUR_GITHUB_EMAIL

# S3 credentials
kubectl create secret generic s3-secrets \
  --from-literal=S3_ENDPOINT_URL=your-s3-endpoint \
  --from-literal=AWS_ACCESS_KEY_ID=your-access-key \
  --from-literal=AWS_SECRET_ACCESS_KEY=your-secret-key \
  --from-literal=S3_BUCKET=your-bucket-name
```

### ğŸ›  3. Create ConfigMap
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: prj-configmap
data:
  MATRIX_SIZES: "4000,5000,10000"
  PROCESSING_MODE: "matrix"  # or "image"
  RAW_IMAGES_FOLDER: "RawImages"
  PROCESSED_IMAGES_FOLDER: "ProcessedImages"
  RESULTS_FOLDER: "benchmark_results"
```
Apply with:
```bash
kubectl apply -f prj-configmap.yml
```

### ğŸš€ 4. Launch the Application
```bash
kubectl apply -f manifest.yml
```

---

## ğŸ”„ CI/CD Pipeline
âœ… **Triggers on version tags (v*.*.*)**  
âœ… **Uses NVIDIA CUDA 11.8.0 base image**  
âœ… **Pushes to GitHub Container Registry**  
âœ… **Tags images with semantic version and Git SHA**  

### ğŸš€ Triggering a Build
```bash
git tag v1.0.0
git push origin v1.0.0
```

---

## ğŸ” Monitoring and Troubleshooting

### ğŸ“Œ Pod Status and Logs
```bash
# Check pod status
kubectl get pods
kubectl describe pod k8s-test

# View logs
kubectl logs -f k8s-test

# Check GPU status
kubectl exec -it k8s-test -- nvidia-smi
```

### âš ï¸ Common Issues and Solutions
1. **GPU Not Detected**  
   ğŸ”¹ Verify runtime class configuration  
   ğŸ”¹ Check NVIDIA device plugin status  
   ```bash
   kubectl get pods -n kube-system | grep nvidia-device-plugin
   ```
2. **S3 Connection Issues**  
   ğŸ”¹ Verify endpoint and credentials  
   ğŸ”¹ Check network connectivity  
   ğŸ”¹ Review exponential backoff settings  
3. **Performance Optimization**  
   ğŸ”¹ Monitor GPU memory usage  
   ğŸ”¹ Adjust batch sizes for image processing  
   ğŸ”¹ Consider matrix size limitations  

---

## ğŸ License
ğŸ“œ **Unicas & Seeweb**

